{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from transformers import SegformerImageProcessor\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# Internal Imports\n",
    "from config import segformer_inference_config\n",
    "from helper.utils import visualize_batch_overlay,filter_multi_lesions,calculate_metrics_ind\n",
    "from helper.data_loader import BUSIDataset,UDIATDataset\n",
    "# Autoreload jupyter extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Global Variables\n",
    "RESULTS_DIR = \"results_evaluation\"\n",
    "GPU_IDX = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paths(base_folder: str = \"dataset_5folds.npz\") -> list[list, list]:\n",
    "    # Load the busi dataset\n",
    "    loaded_folds = np.load(base_folder, allow_pickle=True)\n",
    "    # Check available fold names\n",
    "    print(\"Available folds:\", list(loaded_folds.keys()))\n",
    "\n",
    "    return loaded_folds\n",
    "\n",
    "def get_udiat_loaders(loaded_folds,\n",
    "                    BATCH_SIZE = 32):\n",
    "    list_of_train_loaders = []\n",
    "    list_of_val_loaders = []\n",
    "    list_of_test_loaders = []\n",
    "\n",
    "    for fold_name in range(5):\n",
    "        # Load a specific fold (e.g., Fold 0)\n",
    "        fold = loaded_folds[f\"fold_{fold_name}\"].item()\n",
    "\n",
    "        # Extract train, validation, and test data from Fold 0\n",
    "        train_data = list(map(tuple, fold[\"train\"]))\n",
    "        val_data = list(map(tuple, fold[\"val\"]))\n",
    "        test_data = list(map(tuple, fold[\"test\"]))\n",
    "        # Print dataset sizes\n",
    "        # print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "        # Create Datasets & Dataloaders\n",
    "        # transform = transforms.Compose([transforms.ToTensor()])\n",
    "        # Initialize image processor\n",
    "        transforms = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.Blur(blur_limit=3, p=0.3),\n",
    "        # Normalize to ImageNet mean/std if needed\n",
    "        # A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "                    # std=0.5),\n",
    "        # ToTensorV2(),  # Converts image and mask to torch.Tensor\n",
    "        ])\n",
    "        image_processor = SegformerImageProcessor(\n",
    "            reduce_labels=False,\n",
    "            do_normalize=False,\n",
    "            do_rescale=False,\n",
    "            size={\"height\": 256, \"width\": 256},\n",
    "        )\n",
    "        train_dataset = UDIATDataset(train_data,transform=transforms, image_processor=image_processor)\n",
    "        val_dataset = UDIATDataset(val_data,transform=transforms, image_processor=image_processor)\n",
    "        test_dataset = UDIATDataset(test_data,transform=transforms, image_processor=image_processor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        list_of_train_loaders.append(train_loader)\n",
    "        list_of_val_loaders.append(val_loader)\n",
    "        list_of_test_loaders.append(test_loader)\n",
    "\n",
    "    return (\n",
    "        list_of_train_loaders,\n",
    "        list_of_val_loaders,\n",
    "        list_of_test_loaders,\n",
    "        train_dataset,\n",
    "    )\n",
    "\n",
    "def get_busi_loader(\n",
    "            loaded_data,\n",
    "            BATCH_SIZE = 32\n",
    "            \n",
    "            ):\n",
    "\n",
    "    train_data = loaded_data[\"train\"]\n",
    "    val_data = loaded_data[\"val\"]\n",
    "    test_data = loaded_data[\"test\"]\n",
    "\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "    image_processor = SegformerImageProcessor(\n",
    "        reduce_labels=False,\n",
    "        do_normalize=False,\n",
    "        do_rescale=False,\n",
    "        size={\"height\": 256, \"width\": 256},\n",
    "    )\n",
    "    train_dataset = BUSIDataset(*zip(*train_data), image_processor=image_processor)\n",
    "    val_dataset = BUSIDataset(*zip(*val_data), image_processor=image_processor)\n",
    "    test_dataset = BUSIDataset(*zip(*test_data), image_processor=image_processor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_segformer(\n",
    "    dataloader=None,\n",
    "    MODEL_NAME=None,\n",
    "    SAVE_DIR=None,\n",
    "    post_processing_fns: dict = None,\n",
    "    SAVE_FIGURES=True,\n",
    "    DATASET_NAME=\"CUSTOM\",\n",
    "    plots_title_model_text: str = None,\n",
    "):\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model\n",
    "    loaded_model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        # f\"/home/user/data/phyusformer_data/weights/{MODEL_NAME}\",\n",
    "        f\"weights/{MODEL_NAME}\",\n",
    "        return_dict=False,\n",
    "        num_labels=2,  # Assuming binary segmentation (Background, Foreground)\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "    model = loaded_model.to(device)\n",
    "    list_of_test_metrics_per_batch = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        metadata = batch[\"metadata\"]\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            image = batch[\"pixel_values\"].to(device)  # Shape: (B, 3, H, W)\n",
    "            logits = model(image)[0]  # Output shape: (B, 2, H, W)\n",
    "        if post_processing_fns['activation_fn']=='sigmoid':\n",
    "            pr_masks = logits.sigmoid()  # Convert logits to probabilities\n",
    "        elif post_processing_fns['activation_fn']=='softmax':\n",
    "            pr_masks = logits.softmax(dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function provided\")\n",
    "\n",
    "        # Resize mask to match GT dimensions\n",
    "        mask = torch.nn.functional.interpolate(\n",
    "            pr_masks, size=(256, 256), mode=\"bilinear\", align_corners=False\n",
    "        )  # Shape: (B, 2, 256, 256)\n",
    "\n",
    "        # Convert (B, 2, H, W) â†’ (B, 1, H, W) by selecting the second channel (foreground)\n",
    "        mask = mask[:, 1:2, :, :]  # Now shape is (B, 1, 256, 256)\n",
    "        mask = (mask > post_processing_fns[\"threshold\"]).to(torch.uint8)  # Apply thresholding\n",
    "\n",
    "        # Apply multi-lesion filtering if enabled\n",
    "        if post_processing_fns['REMOVE_SMALL_LESIONS']:\n",
    "            mask_np = mask.cpu().numpy()\n",
    "            mask_np = np.array(\n",
    "                [filter_multi_lesions(m.squeeze()) for m in mask_np]\n",
    "            )  # Efficiently apply filtering\n",
    "            mask = torch.tensor(mask_np).unsqueeze(1).to(device)\n",
    "        \n",
    "        batch_metrics = calculate_metrics_ind(\n",
    "            outputs=mask.to(device),\n",
    "            targets=batch[\"labels\"].to(device),\n",
    "            threshold=post_processing_fns[\"threshold\"],\n",
    "        )\n",
    "        visualize_batch_overlay(\n",
    "            batch,\n",
    "            mask,\n",
    "            num_imgs=image.shape[0],\n",
    "            preview=False,\n",
    "            MODEL_NAME=plots_title_model_text,\n",
    "            threshold=post_processing_fns[\"threshold\"],\n",
    "            save=SAVE_FIGURES,\n",
    "            save_dir=SAVE_DIR,\n",
    "            batch_metrics=batch_metrics,\n",
    "        )\n",
    "\n",
    "        image_paths = metadata[\"image_path\"]\n",
    "        mask_paths = list(batch[\"metadata\"][\"mask_path\"])\n",
    "        tumor_class = metadata[\"label\"]\n",
    "        batch_metrics[\"image_path\"] = image_paths\n",
    "        batch_metrics[\"mask_path\"] = mask_paths\n",
    "        batch_metrics[\"tumor_class\"] = tumor_class\n",
    "        pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "        df = pd.DataFrame(batch_metrics)\n",
    "        list_of_test_metrics_per_batch.append(df)\n",
    "\n",
    "    # Save results\n",
    "    df = pd.concat(list_of_test_metrics_per_batch, ignore_index=True)\n",
    "    print(\"Inference done!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of UDIAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters from config\n",
    "selected_dataset = \"udiat\"\n",
    "# selected_model = \"physformer\" # select either physformer, baseline_model\n",
    "selected_model = \"baseline_model\"  # select either physformer, baseline_model\n",
    "# Load the parameters from config\n",
    "DATA_DIR = segformer_inference_config[selected_dataset][\"data_path\"]\n",
    "FOLD_ID_UDIAT = segformer_inference_config[selected_dataset][\"fold_id\"]\n",
    "BATCH_SIZE = segformer_inference_config[selected_dataset][selected_model][\"BATCH_SIZE\"]\n",
    "MODEL_PATH = segformer_inference_config[selected_dataset][selected_model][\"path\"]\n",
    "POST_PROCESSING_FN = segformer_inference_config[selected_dataset][selected_model][\n",
    "    \"post_processing\"\n",
    "]\n",
    "\n",
    "# Visualization parameters\n",
    "SAVE_FIGURES = True\n",
    "PLOTS_PATHS = os.path.join(RESULTS_DIR, MODEL_PATH)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_PATHS, exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "loaded_folds = load_paths(DATA_DIR)\n",
    "# Load the updated folds\n",
    "_,_,list_of_test_loaders,_ = (\n",
    "    get_udiat_loaders(loaded_folds, BATCH_SIZE=BATCH_SIZE)\n",
    ")\n",
    "print(f\"Testing Fold {FOLD_ID_UDIAT}\")\n",
    "df = test_segformer(\n",
    "    dataloader=list_of_test_loaders[FOLD_ID_UDIAT],\n",
    "    MODEL_NAME=MODEL_PATH,\n",
    "    SAVE_DIR=PLOTS_PATHS,\n",
    "    post_processing_fns=POST_PROCESSING_FN,\n",
    "    SAVE_FIGURES=SAVE_FIGURES,\n",
    "    plots_title_model_text = selected_model,\n",
    ")\n",
    "df.to_csv(f\"results/{MODEL_PATH}_inference_metrics_UDIAT_ALL_FOLDS.csv\", index=False)\n",
    "df_summary = df.drop(columns=[\"image_path\", \"mask_path\"])[[\"dice\", \"hd95\",\"iou\"]].describe()\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalaution BUSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = f\"segformer-mit-b5_dataset_four_Fold_4freeze_encoder_FalseUDIAT_FOLD_ID_{FOLD_ID_UDIAT}NEW_CHALLENGE_LR_2e-05_Without_Transformations\"\n",
    "# # MODEL_PATH = f\"segformer-mit-b5_UDIAT_from_scratch_Fold_{FOLD_ID_UDIAT}\"\n",
    "# Load the parameters from config\n",
    "selected_dataset = \"busi\"\n",
    "selected_model = \"physformer\" # select either physformer, baseline_model\n",
    "# selected_model = \"baseline_model\"  # select either physformer, baseline_model\n",
    "# Load the parameters from config\n",
    "DATA_DIR = segformer_inference_config[selected_dataset][\"data_path\"]\n",
    "FOLD_ID_BUSI = segformer_inference_config[selected_dataset][\"fold_id\"]\n",
    "BATCH_SIZE = segformer_inference_config[selected_dataset][selected_model][\"BATCH_SIZE\"]\n",
    "MODEL_PATH = segformer_inference_config[selected_dataset][selected_model][\"path\"]\n",
    "POST_PROCESSING_FN = segformer_inference_config[selected_dataset][selected_model][\n",
    "    \"post_processing\"\n",
    "]\n",
    "\n",
    "# Visualization parameters\n",
    "SAVE_FIGURES = True\n",
    "PLOTS_PATHS = os.path.join(RESULTS_DIR, MODEL_PATH)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_PATHS, exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "loaded_folds = load_paths(DATA_DIR)\n",
    "# Load the updated folds\n",
    "_,_,test_loader,_ = (\n",
    "    get_busi_loader(loaded_folds, BATCH_SIZE=BATCH_SIZE)\n",
    ")\n",
    "df = test_segformer(\n",
    "    dataloader=test_loader,\n",
    "    MODEL_NAME=MODEL_PATH,\n",
    "    SAVE_DIR=PLOTS_PATHS,\n",
    "    post_processing_fns=POST_PROCESSING_FN,\n",
    "    SAVE_FIGURES=SAVE_FIGURES,\n",
    ")\n",
    "df.to_csv(f\"results/{MODEL_PATH}_inference_metrics_BUSI_ALL_FOLDS.csv\", index=False)\n",
    "df_summary = df.drop(columns=[\"image_path\", \"mask_path\"])[[\"dice\", \"hd95\",\"iou\"]].describe()\n",
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haris_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
